# This is a basic workflow to help you get started with Actions

name: Scrape data

# Controls when the action will run.
on:
  repository_dispatch:
    types: rescrape
  workflow_dispatch:
  schedule:
    # Once every hour
    - cron: "0 * * * *"

env:
  SCRAPER_DIR: quacs-oxy-scraper

jobs:
  scrape-semesters:
    name: "Scrape semesters"
    runs-on:
      ubuntu-latest
    steps:
      - name: Checkout scrapers
        uses: actions/checkout@v3
        with:
          path: 'quacs-oxy-scraper'
          repository: 'NickyBoy89/quacs-oxy-scraper'
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      - name: Setup pip requirements
        run: |
          sudo apt-get install -y libxml2 libxml2-dev libxslt-dev
          python -m pip install --upgrade pip
          pip install -r quacs-oxy-scraper/requirements.txt
          cp quacs-oxy-scraper/transform.go .
      - name: Scrape
        run: |
          make -C $SCRAPER_DIR semesters.json
          cp $SCRAPER_DIR/semesters.json .
      - name: Upload scraped data
        uses: actions/upload-artifact@v4
        with:
          name: semesters
          path: |
            semesters.json
            transform.go
  scrape-faculty-directory:
    name: "Scrape faculty directory"
    runs-on:
      ubuntu-latest
    steps:
      - name: Checkout scrapers
        uses: actions/checkout@v3
        with:
          path: 'quacs-oxy-scraper'
          repository: 'NickyBoy89/quacs-oxy-scraper'
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      - name: Setup pip requirements
        run: |
          sudo apt-get install -y libxml2 libxml2-dev libxslt-dev
          python -m pip install --upgrade pip
          pip install -r quacs-oxy-scraper/requirements.txt
          ls
      - name: Scrape
        run: |
          make -C $SCRAPER_DIR faculty.json
          cp $SCRAPER_DIR/faculty.json .
      - name: Upload scraped data
        uses: actions/upload-artifact@v4
        with:
          name: faculty
          path: faculty.json

  # These things depend on semesters.json, run them after the [scrape-semesters] job is done
  scrape-catalog:
    name: "Scrape catalog"
    runs-on:
      ubuntu-latest
    needs: [scrape-semesters]
    steps:
      - name: Checkout scrapers
        uses: actions/checkout@v3
        with:
          path: 'quacs-oxy-scraper'
          repository: 'NickyBoy89/quacs-oxy-scraper'
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      - name: Setup pip requirements
        run: |
          sudo apt-get install -y libxml2 libxml2-dev libxslt-dev
          python -m pip install --upgrade pip
          pip install -r quacs-oxy-scraper/requirements.txt
          ls
      - name: Get scraped data
        uses: actions/download-artifact@v4
        with:
          name: semesters
          path: "./semesters"
      - name: Scrape
        run: |
          cp semesters/semesters.json .
          make -C $SCRAPER_DIR catalog.json
          cp $SCRAPER_DIR/catalog.json .
      - name: Upload scraped data
        uses: actions/upload-artifact@v4
        with:
          name: catalog
          path: catalog.json
  scrape-prerequisites:
    name: "Scrape prerequisites"
    runs-on:
      ubuntu-latest
    needs: [scrape-semesters]
    steps:
      - name: Checkout scrapers
        uses: actions/checkout@v3
        with:
          path: 'quacs-oxy-scraper'
          repository: 'NickyBoy89/quacs-oxy-scraper'
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      - name: Setup pip requirements
        run: |
          sudo apt-get install -y libxml2 libxml2-dev libxslt-dev
          python -m pip install --upgrade pip
          pip install -r quacs-oxy-scraper/requirements.txt
          ls
      - name: Get scraped data
        uses: actions/download-artifact@v4
        with:
          name: semesters
          path: "./semesters"
      - name: Scrape
        run: |
          cp semesters/semesters.json .
          make -C $SCRAPER_DIR prerequisites.json
          cp $SCRAPER_DIR/prerequisites.json .
      - name: Upload scraped data
        uses: actions/upload-artifact@v4
        with:
          name: prerequisites
          path: prerequisites.json
  scrape-schools:
    name: "Scrape schools"
    runs-on:
      ubuntu-latest
    needs: [scrape-semesters]
    steps:
      - name: Checkout scrapers
        uses: actions/checkout@v3
        with:
          path: 'quacs-oxy-scraper'
          repository: 'NickyBoy89/quacs-oxy-scraper'
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      - name: Setup pip requirements
        run: |
          sudo apt-get install -y libxml2 libxml2-dev libxslt-dev
          python -m pip install --upgrade pip
          pip install -r quacs-oxy-scraper/requirements.txt
      - name: Get scraped data
        uses: actions/download-artifact@v4
        with:
          name: semesters
          path: "./semesters"
      - name: Scrape
        run: |
          cp semesters/semesters.json .
          make -C $SCRAPER_DIR schools.json
          cp $SCRAPER_DIR/schools.json .
      - name: Upload scraped data
        uses: actions/upload-artifact@v4
        with:
          name: schools
          path: schools.json

  # This depends on semesters.json and catalog.json, so wait on [scrape-semesters] and [scrape-catalog]
  scrape-sis:
    name: "Scrape SIS"
    runs-on:
      ubuntu-latest
    needs: [scrape-semesters, scrape-catalog]
    steps:
      - name: Checkout scrapers
        uses: actions/checkout@v3
        with:
          path: 'quacs-oxy-scraper'
          repository: 'NickyBoy89/quacs-oxy-scraper'
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      - name: Setup pip requirements
        run: |
          sudo apt-get install -y libxml2 libxml2-dev libxslt-dev
          python -m pip install --upgrade pip
          pip install -r quacs-oxy-scraper/requirements.txt
          ls
      - name: Get scraped data
        uses: actions/download-artifact@v4
        with:
          name: semesters
          path: "./semesters"
      - name: Get more data
        uses: actions/download-artifact@v4
        with:
          name: catalog
          path: "./catalog"
      - name: Scrape
        run: |
          cp catalog/catalog.json .
          cp semesters/semesters.json .
          make -C $SCRAPER_DIR courses.json
          cp $SCRAPER_DIR/courses.json .
          cp $SCRAPER_DIR/mod.rs .
      - name: Upload scraped data
        uses: actions/upload-artifact@v4
        with:
          name: courses
          path: |
            courses.json
            mod.rs
  commit-data:
    name: Commit changes
    continue-on-error: true
    runs-on: ubuntu-latest
    needs: [scrape-semesters, scrape-faculty-directory, scrape-catalog, scrape-prerequisites, scrape-schools, scrape-sis]
    steps:
      - name: Checkout scrapers
        uses: actions/checkout@v3
        with:
          path: 'quacs-oxy-scraper'
          repository: 'NickyBoy89/quacs-oxy-scraper'
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      - name: Setup pip requirements
        run: |
          sudo apt-get install -y libxml2 libxml2-dev libxslt-dev
          python -m pip install --upgrade pip
          pip install -r quacs-oxy-scraper/requirements.txt
          ls
      - name: Setup Go
        run: |
          sudo apt-get install golang
      - name: Checkout data
        uses: actions/checkout@v3
        with:
          path: 'data'
          repository: 'NickyBoy89/quacs-oxy-data'
          clean: true
      - name: Get scraped data
        uses: actions/download-artifact@v4
      - name: Generate meta json file
        run: echo {\"last_updated\":\"$(date --iso-8601=seconds -u)\"} > data/meta.json
      - name: Find whats in the artifact
        run: |
          cd courses
          ls
      - name: Copy data from scrapers to data directory
        run: |
          cd semesters
          go run transform.go
          cd ../
          current_semester=$(tail -n 1 semesters/semesters.json)
          mkdir -p data/semester_data/${current_semester}
          cp courses/courses.json courses/mod.rs data/semester_data/${current_semester}
          cp catalog/catalog.json data/semester_data/${current_semester}
          #cp rmp/rmp.json data/semester_data/${current_semester}
          cp prerequisites/prerequisites.json data/semester_data/${current_semester}
          cp schools/schools.json data/semester_data/${current_semester}
          cp faculty/faculty.json data
      - name: Generate prerequisites graph on all the data
        run: |
          python3 quacs-oxy-scraper/prerequisites_graph.py data/semester_data prereq_graph.json
          cp prereq_graph.json data
          ls
        continue-on-error: true
      - name: Commit new data
        run: |
          current_semester=$(tail -n 1 semesters/semesters.json)
          echo $current_semester
          cd data
          git config user.name "Quacs Oxy Scraper" && git config user.email "scraper@nicholasnovak.io"
          git add faculty.json
          git add prereq_graph.json
          git add semester_data/${current_semester}/courses.json semester_data/${current_semester}/mod.rs
          git add semester_data/${current_semester}/prerequisites.json
          git add semester_data/${current_semester}/schools.json
          git add semester_data/${current_semester}/catalog.json
          git add meta.json
          git commit -m "$(date -u)"
          git push --force
      - name: Trigger a site build with the new data
        run: |
          curl -XPOST -u "${{ secrets.PAT_USERNAME}}:${{secrets.PAT_TOKEN}}" -H "Accept: application/vnd.github.everest-preview+json" -H "Content-Type: application/json" https://api.github.com/repos/NickyBoy89/quacs-oxy/dispatches --data '{"event_type": "scrape_complete"}'
